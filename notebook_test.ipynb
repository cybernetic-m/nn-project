{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS PART TO TEST DIFFERENT MODELS!!!\n",
    "# The only parameters to change are the directory path of the model to test\n",
    "# and the Activation Function type\n",
    "# ****---------------------------------------****\n",
    "actual_dir = \"./results_tmp/CkTIM_TAB6_60epochs\"\n",
    "AF_TYPE = 'sin'\n",
    "HIDDEN_SCALE = 1\n",
    "N_TAB = 6\n",
    "# ****---------------------------------------****\n",
    "# These other are automatic based on the name of the directory!!!\n",
    "# Ex. CkkTIM_aug, CkTIM (no augmentation) ...\n",
    "GEN_TYPE = 'convKan' if 'Ckk' in actual_dir else 'conv'\n",
    "CK = 'Ck' in actual_dir \n",
    "AUG = 'aug' in actual_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import dataloader.utils as utils\n",
    "import dataloader.dataset as dataset\n",
    "from dataloader.preprocessing import Preprocessing\n",
    "from model.ctim import CTIM\n",
    "from testing.test import test as test\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Check if Hydra is initialized\n",
    "if GlobalHydra().is_initialized():\n",
    "    # Clear the Hydra instance if it is initialized\n",
    "    GlobalHydra.instance().clear()\n",
    "    print(\"Hydra instance was initialized and has been cleared.\")\n",
    "else:\n",
    "    # Initialize\n",
    "    print(\"Hydra now initialized!\")\n",
    "\n",
    "# Initialization and Load configuration\n",
    "initialize(config_path=\"./conf\", job_name=\"notebook_nn_exam\", version_base=None)\n",
    "cfg = compose(config_name=\"config\")\n",
    "\n",
    "# Set the devide mode on GPU (if available CUDA for Nvidia and  MPS for Apple Silicon) or CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Your device is:\", device)\n",
    "\n",
    "# Load the hyperparameters of the model\n",
    "DROPOUT_RATE = cfg.model.dropout_rate\n",
    "KERNEL_SIZE = cfg.model.kernel_size\n",
    "N_FILTER = cfg.model.n_filter\n",
    "NUM_FEATURES = cfg.model.num_features\n",
    "OMEGA_0 = cfg.model.omega_0\n",
    "\n",
    "\n",
    "model = CTIM(\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    n_temporal_aware_block=N_TAB,\n",
    "    n_filter=N_FILTER,\n",
    "    in_channels=39,\n",
    "    ck=CK,\n",
    "    generator_type= GEN_TYPE,\n",
    "    num_features=NUM_FEATURES,\n",
    "    num_classes = 7,\n",
    "    omega_0=OMEGA_0,\n",
    "    af_type=AF_TYPE,\n",
    "    hidden_scale=HIDDEN_SCALE,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model_path = actual_dir + '/model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = utils.count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AUG == True:\n",
    "    test_path = './dataset/EMOVO_aug/test'\n",
    "    test_dataset = dataset.EMOVO_Dataset(test_path, feature_extract=True, mfcc_np=False, device=device)\n",
    "\n",
    "    # Initialization of the dataloader\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Loss Function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialization of the test metrics dictionary\n",
    "    test_metrics_dict = {\n",
    "        \"model\" : [model.model_name],\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"recall\": [],\n",
    "        \"precision\": [],\n",
    "        \"f1_score\": [],\n",
    "        \"inference_time_one_sample\": [],\n",
    "        \"inference_time_tot\": [],\n",
    "        \"trainable_parameters\": [parameters]\n",
    "    }\n",
    "\n",
    "    cm, inference_time_list = test(\n",
    "        model,\n",
    "        model_path,\n",
    "        test_dataloader,\n",
    "        test_metrics_dict,\n",
    "        loss_fn\n",
    "    )\n",
    "\n",
    "elif AUG == False:\n",
    "\n",
    "    test_path = './dataset/EMOVO_split_MFCC/test'\n",
    "    test_dataset = dataset.EMOVO_Dataset(test_path, feature_extract=False, mfcc_np=True, device=device)\n",
    "\n",
    "    # Initialization of the dataloader\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Loss Function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialization of the test metrics dictionary\n",
    "    test_metrics_dict = {\n",
    "        \"model\" : [model.model_name],\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"recall\": [],\n",
    "        \"precision\": [],\n",
    "        \"f1_score\": [],\n",
    "        \"inference_time_one_sample\": [],\n",
    "        \"inference_time_tot\": [],\n",
    "        \"trainable_parameters\": [parameters]\n",
    "    }\n",
    "\n",
    "    cm, inference_time_list = test(\n",
    "        model,\n",
    "        model_path,\n",
    "        test_dataloader,\n",
    "        test_metrics_dict,\n",
    "        loss_fn\n",
    "    )\n",
    "    \n",
    "inference_time_one_sample = round(torch.tensor(inference_time_list).mean().item(),3)\n",
    "inference_time_tot = round(torch.tensor(inference_time_list).sum().item(),3)\n",
    "\n",
    "print(\"Inference Time for 1 sample (average value):\")\n",
    "print(inference_time_one_sample)\n",
    "print(\"Inference Time for all samples of test set:\")\n",
    "print(inference_time_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Accuracy (Training and Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training_metrics = actual_dir + '/training_metrics.json'\n",
    "path_validation_metrics = actual_dir+ '/validation_metrics.json'\n",
    "\n",
    "# load the dictionary {'model': [model_name], 'epoch': [1, 2 ...], 'loss': [1.9, 1.8 ...], 'accuracy': [0.6, 0.7, ...], 'recall': [0.2, 0.3, ...], 'precision': [0.3, 0.4, ...], 'f1-score': [0.5, 0.6, ...]}\n",
    "data_training = utils.load_metrics(path_training_metrics)\n",
    "data_validation = utils.load_metrics(path_validation_metrics)\n",
    "\n",
    "# Load the epochs, loss and accuracy in training and validation for the plots\n",
    "epochs = data_training['epoch']\n",
    "training_loss = data_training['loss']\n",
    "training_accuracy = data_training['accuracy']\n",
    "\n",
    "validation_loss = data_validation['loss']\n",
    "validation_accuracy = data_validation['accuracy']\n",
    "\n",
    "# Plot section\n",
    "# 1st Subplot => Loss in Training and Validation\n",
    "# 2nd Subplot => Accuracy in Training and Validation\n",
    "utils.plot_loss_acc(epochs, training_loss, validation_loss, training_accuracy, validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion Matrix\n",
    "class_names = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
    "utils.plot_confusion_matrix(cm, class_names, cmap='rocket')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
