{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dIRawMyjYAz"
      },
      "source": [
        "⚠️Clone the repository to use all the functions needed by the main code⚠️\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvEJSRQzjVVO",
        "outputId": "621797ba-2595-461d-e6ec-8c898391b5dd"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    mode = 'colab'\n",
        "except:\n",
        "    mode = 'local'\n",
        "\n",
        "if mode == 'colab':\n",
        "    !git clone \"https://github.com/cybernetic-m/nn-project.git\"\n",
        "    !pip install hydra-core --upgrade convkan\n",
        "else:\n",
        "    print(\"You are running locally!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZNKzy8qbbu2"
      },
      "source": [
        "# IMPORT AND INITIALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKakfnMRbKum"
      },
      "outputs": [],
      "source": [
        "# Import for config.yaml file\n",
        "from hydra import initialize, compose\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "if mode == 'colab':\n",
        "    sys.path.append('/content/nn-project/dataloader')\n",
        "    sys.path.append('/content/nn-project/model')\n",
        "    sys.path.append('/content/nn-project/module')\n",
        "    sys.path.append('/content/nn-project/training')\n",
        "    sys.path.append('/content/nn-project/testing')\n",
        "    from preprocessing import Preprocessing\n",
        "    import utils\n",
        "    import dataset\n",
        "    from ctim import CTIM\n",
        "    from train import *\n",
        "    from test import *\n",
        "\n",
        "\n",
        "if mode == 'local':\n",
        "    import dataloader.utils as utils\n",
        "    import dataloader.dataset as dataset\n",
        "    from dataloader.preprocessing import Preprocessing\n",
        "    from model.ctim import CTIM\n",
        "    from training.train import train as train\n",
        "    from testing.test import test as test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzpebiXBPJE-"
      },
      "source": [
        "Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3f4K2m8PIrc"
      },
      "outputs": [],
      "source": [
        "# Set the seed\n",
        "seed = 46\n",
        "\n",
        "# Set seed for torch, numpy and random libraries\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Set the devide mode on GPU (if available CUDA for Nvidia and  MPS for Apple Silicon) or CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mV42Zq-UKCz"
      },
      "source": [
        "## Download and Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV_poPYiccs2",
        "outputId": "e50c5a1d-7044-4167-99c3-48ec2f05c711"
      },
      "outputs": [],
      "source": [
        "link_dataset = \"https://drive.google.com/file/d/1nzKBta2M3khw7Ql_S7atYg-H-bWDiOxr/view?usp=drive_link\"\n",
        "gdrive_link = \"https://drive.google.com/uc?export=download&id=\"\n",
        "\n",
        "if mode == 'colab':\n",
        "    destination_dir = \"/content/emovo.zip\"\n",
        "    extract_dir = '/content/dataset'\n",
        "    emovo_dir = '/content/dataset/EMOVO'\n",
        "    emovo_split_dir = '/content/dataset/EMOVO_split'\n",
        "elif mode == 'local':\n",
        "    destination_dir = \"./emovo.zip\"\n",
        "    extract_dir = \"./dataset\"\n",
        "    emovo_dir = \"./dataset/EMOVO\"\n",
        "    emovo_split_dir = './dataset/EMOVO_split'\n",
        "\n",
        "utils.download_dataset(link_dataset, destination_dir, gdrive_link, extract_dir)\n",
        "\n",
        "utils.dataset_split(emovo_dir, extract_dir, 0.7, 0.2, 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if mode == 'colab':\n",
        "    utils.dataset_split_mfcc('./nn-project/EMOVO.npy', extract_dir, 0.7, 0.2, 0.1)\n",
        "elif mode == 'local':\n",
        "    utils.dataset_split_mfcc('./EMOVO.npy', extract_dir, 0.7, 0.2, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrZ8n_tp2nfh"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBRzIeeY2nfh",
        "outputId": "b7a2bfe4-c0e0-40ab-94c7-f9a3afffa6d9"
      },
      "outputs": [],
      "source": [
        "preprocessing = Preprocessing(device=device)\n",
        "\n",
        "utils.augment_data(emovo_split_dir, extract_dir, preprocessing, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVRKvN26UUq9"
      },
      "source": [
        "## Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRn6VibgUXm9",
        "outputId": "491fc476-55ab-423a-f653-619cae3944dc"
      },
      "outputs": [],
      "source": [
        "train_path = os.path.join(extract_dir, 'EMOVO_split', 'train')\n",
        "test_path = os.path.join(extract_dir, 'EMOVO_split', 'test')\n",
        "val_path = os.path.join(extract_dir, 'EMOVO_split', 'val')\n",
        "\n",
        "train_dataset = dataset.EMOVO_Dataset(train_path, feature_extract=False, mfcc_np=False, device=device)\n",
        "test_dataset = dataset.EMOVO_Dataset(test_path, feature_extract=False, mfcc_np=False, device=device)\n",
        "val_dataset = dataset.EMOVO_Dataset(val_path, feature_extract=False, mfcc_np=False, device=device)\n",
        "\n",
        "train_aug_path = os.path.join(extract_dir, 'EMOVO_aug', 'train')\n",
        "test_aug_path = os.path.join(extract_dir, 'EMOVO_aug', 'test')\n",
        "val_aug_path = os.path.join(extract_dir, 'EMOVO_aug', 'val')\n",
        "\n",
        "train_aug_dataset = dataset.EMOVO_Dataset(train_aug_path, feature_extract=False, mfcc_np=False, device=device)\n",
        "test_aug_dataset = dataset.EMOVO_Dataset(test_aug_path,feature_extract=False, mfcc_np=False, device=device)\n",
        "val_aug_dataset = dataset.EMOVO_Dataset(val_aug_path, feature_extract=False, mfcc_np=False, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ9URMKkfQmU"
      },
      "source": [
        "Example of audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "mcblPPkeZw35",
        "outputId": "f79994e1-f311-4cb7-f112-de385323b3ae"
      },
      "outputs": [],
      "source": [
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "random_num = random.randint(1, train_dataset.__len__())\n",
        "data, label = train_dataset[random_num]\n",
        "\n",
        "print(\"Tensor of shape:\",data[0].shape, \"Sample Rate:\", data[1])\n",
        "print(\"Class:\", classes[label], \"\\n\")\n",
        "\n",
        "# Waveform\n",
        "# Compute the average of both channels to get a mono waveform\n",
        "mono_waveform = data[0].mean(dim=0)\n",
        "num_samples = mono_waveform.shape[0]\n",
        "sample_rate = data[1]\n",
        "time_axis = np.linspace(0, num_samples / sample_rate, num_samples)\n",
        "\n",
        "# Play the audio\n",
        "display(Audio(mono_waveform.cpu().numpy(), rate=sample_rate))\n",
        "\n",
        "# Plot the averaged (mono) waveform\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_axis, mono_waveform.cpu().numpy())\n",
        "plt.title('Waveform (Averaged Mono)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSzFkhBu2nfi"
      },
      "source": [
        "Example of augmented audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5XiV4x82nfi"
      },
      "outputs": [],
      "source": [
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "random_num = random.randint(1, train_dataset.__len__())\n",
        "data, label = train_aug_dataset[random_num]\n",
        "\n",
        "print(\"Tensor of shape:\",data[0].shape, \"Sample Rate:\", data[1])\n",
        "print(\"Class:\", classes[label], \"\\n\")\n",
        "\n",
        "# Waveform\n",
        "# Compute the average of both channels to get a mono waveform\n",
        "mono_waveform = data[0].mean(dim=0)\n",
        "num_samples = mono_waveform.shape[0]\n",
        "sample_rate = data[1]\n",
        "time_axis = np.linspace(0, num_samples / sample_rate, num_samples)\n",
        "\n",
        "# Play the audio\n",
        "display(Audio(mono_waveform.cpu().numpy(), rate=sample_rate))\n",
        "\n",
        "# Plot the averaged (mono) waveform\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_axis, mono_waveform.cpu().numpy())\n",
        "plt.title('Waveform (Averaged Mono)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnwkpxVjIDni"
      },
      "source": [
        "Data distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "q3Hs-83fIHPT",
        "outputId": "f64ac95c-b03e-4b4b-9156-c7e93f23e3b8"
      },
      "outputs": [],
      "source": [
        "train_counts = train_dataset.get_info()\n",
        "test_counts = test_dataset.get_info()\n",
        "val_counts = val_dataset.get_info()\n",
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(16, 4))\n",
        "\n",
        "ax[0].bar(classes, train_counts, color='limegreen')\n",
        "ax[0].set_title(\"Data distribution in Training Set\")\n",
        "ax[0].set_xlabel(\"Classes\")\n",
        "ax[0].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[0].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[1].bar(classes, test_counts, color='seagreen')\n",
        "ax[1].set_title(\"Data distribution in Test Set\")\n",
        "ax[1].set_xlabel(\"Classes\")\n",
        "ax[1].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[1].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[2].bar(classes, val_counts, color='olive')\n",
        "ax[2].set_title(\"Data distribution in Validation Set\")\n",
        "ax[2].set_xlabel(\"Classes\")\n",
        "ax[2].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[2].set_ylabel(\"Number of samples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzyjYYHp2nfi"
      },
      "source": [
        "Data augmented distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "WUqtdsOf2nfi",
        "outputId": "3d60a842-b1f0-41c5-f68d-d605dbfcbd14"
      },
      "outputs": [],
      "source": [
        "train_aug_counts = train_aug_dataset.get_info()\n",
        "test_aug_counts = test_aug_dataset.get_info()\n",
        "val_aug_counts = val_aug_dataset.get_info()\n",
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(16, 4))\n",
        "\n",
        "ax[0].bar(classes, train_aug_counts, color='limegreen')\n",
        "ax[0].set_title(\"Data distribution in Training Set\")\n",
        "ax[0].set_xlabel(\"Classes\")\n",
        "ax[0].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[0].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[1].bar(classes, test_aug_counts, color='seagreen')\n",
        "ax[1].set_title(\"Data distribution in Test Set\")\n",
        "ax[1].set_xlabel(\"Classes\")\n",
        "ax[1].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[1].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[2].bar(classes, val_aug_counts, color='olive')\n",
        "ax[2].set_title(\"Data distribution in Validation Set\")\n",
        "ax[2].set_xlabel(\"Classes\")\n",
        "ax[2].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[2].set_ylabel(\"Number of samples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6u2yOd0iuRt"
      },
      "source": [
        "# MODEL INITIALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK9-Zzs-iuRt",
        "outputId": "e32700b7-b64a-4601-cd21-6b343b4a1365"
      },
      "outputs": [],
      "source": [
        "# Check if Hydra is initialized\n",
        "if GlobalHydra().is_initialized():\n",
        "    # Clear the Hydra instance if it is initialized\n",
        "    GlobalHydra.instance().clear()\n",
        "    print(\"Hydra instance was initialized and has been cleared.\")\n",
        "else:\n",
        "    # Initialize\n",
        "    print(\"Hydra now initialized!\")\n",
        "\n",
        "# Initialization and Load configuration\n",
        "if mode == 'local':\n",
        "  initialize(config_path=\"./conf\", job_name=\"notebook_nn_exam\", version_base=None)\n",
        "  cfg = compose(config_name=\"config\")\n",
        "\n",
        "elif mode == 'colab':\n",
        "  initialize(config_path=\"./nn-project/conf\", job_name=\"notebook_nn_exam\", version_base=None)\n",
        "  cfg = compose(config_name=\"config\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Vn5O9hp_iuRt"
      },
      "outputs": [],
      "source": [
        "# Load the hyperparameters of the model\n",
        "DROPOUT_RATE = cfg.model.dropout_rate\n",
        "KERNEL_SIZE = cfg.model.kernel_size\n",
        "N_TAB = cfg.model.n_temporal_aware_block\n",
        "N_FILTER = cfg.model.n_filter\n",
        "NUM_FEATURES = cfg.model.num_features\n",
        "CK = cfg.model.ck\n",
        "GEN_TYPE = cfg.model.generator_type\n",
        "OMEGA_0 = cfg.model.omega_0\n",
        "AF_TYPE = cfg.model.af_type\n",
        "AUG = cfg.model.aug\n",
        "HIDDEN_SCALE = cfg.model.hidden_scale\n",
        "\n",
        "\n",
        "model = CTIM(\n",
        "    kernel_size=KERNEL_SIZE,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    n_temporal_aware_block=N_TAB,\n",
        "    n_filter=N_FILTER,\n",
        "    in_channels=39,\n",
        "    ck=CK,\n",
        "    num_features=NUM_FEATURES,\n",
        "    num_classes = 7,\n",
        "    generator_type= GEN_TYPE,\n",
        "    omega_0=OMEGA_0,\n",
        "    af_type=AF_TYPE,\n",
        "    hidden_scale=HIDDEN_SCALE,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUdCPiRZiuRu"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EmPUS-iBiuRu",
        "outputId": "58030685-a642-4cea-ff80-09af8c680bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/100:\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "MPS backend out of memory (MPS allocated: 9.00 GB, other allocations: 49.02 MB, max allowed: 9.07 GB). Tried to allocate 28.04 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 67\u001b[0m\n\u001b[1;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m LEARNING_RATE)\n\u001b[1;32m     65\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39mLR_SCHEDULER, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_metrics_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metrics_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/training/train.py:28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, training_metrics_dict, validation_metrics_dict, training_loader, validation_loader, model, loss_fn, optimizer, plateau_scheduler, cfg)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Compute the average loss and the predictions vs true values\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Train the model for the single epoch\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 28\u001b[0m loss_avg, y_pred_list, y_true_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate the metrics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/training/train_one_epoch.py:26\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(training_loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Compute the loss and the gradient\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#y_pred = torch.argmax(y_pred, dim)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#print(\"y_pred\", y_pred)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#print(\"y_true\", y_true)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_true)\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/model/ctim.py:74\u001b[0m, in \u001b[0;36mCTIM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 74\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctim_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x1)       \n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/model/ctim_net.py:115\u001b[0m, in \u001b[0;36mCTIM_network.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m g_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tab_forward,tab_reverse \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTempAw_Blocks_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTempAw_Blocks_reverse):\n\u001b[0;32m--> 115\u001b[0m     x_forward \u001b[38;5;241m=\u001b[39m \u001b[43mtab_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_forward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     x_reverse \u001b[38;5;241m=\u001b[39m tab_reverse(x_reverse)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m#print(\"skip_out_forward\", x_forward.shape)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m#print(\"skip_out backward\", x_reverse.shape)\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/module/temporal_aware_block.py:106\u001b[0m, in \u001b[0;36mTempAw_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#print(\"x2 spatial drop\",x2.shape)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mck:\n\u001b[0;32m--> 106\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Padding Causal 2\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#print(\"x2\", x2.shape)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x2)\n",
            "File \u001b[0;32m~/Desktop/Neural Network/nn-project/.venv/lib/python3.9/site-packages/torch/nn/functional.py:4552\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4545\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   4546\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[1;32m   4547\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4548\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4549\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_replication_pad(\n\u001b[1;32m   4550\u001b[0m                 \u001b[38;5;28minput\u001b[39m, pad\n\u001b[1;32m   4551\u001b[0m             )\n\u001b[0;32m-> 4552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 9.00 GB, other allocations: 49.02 MB, max allowed: 9.07 GB). Tried to allocate 28.04 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
          ]
        }
      ],
      "source": [
        "# Load the hyperparameters for training\n",
        "EPOCHS = cfg.train.num_epochs\n",
        "BATCH_SIZE = cfg.train.batch_size\n",
        "LEARNING_RATE = cfg.train.learning_rate\n",
        "OPTI = cfg.train.optimizer\n",
        "EARLY_STOPPING = cfg.train.early_stopping\n",
        "PATIENCE = cfg.train.patience\n",
        "LR_SCHEDULER = cfg.train.lr_scheduler\n",
        "LABEL_SMOOTHING = cfg.train.label_smoothing\n",
        "\n",
        "# Initialization of the metrics' dictionary\n",
        "training_metrics_dict = {\n",
        "    \"model\" : [model.model_name],\n",
        "    \"epoch\": [],\n",
        "    \"loss\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"recall\": [],\n",
        "    \"precision\": [],\n",
        "    \"f1_score\": [],\n",
        "}\n",
        "validation_metrics_dict = {\n",
        "    \"model\" : [model.model_name],\n",
        "    \"epoch\": [],\n",
        "    \"loss\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"recall\": [],\n",
        "    \"precision\": [],\n",
        "    \"f1_score\": [],\n",
        "}\n",
        "\n",
        "if AUG == True:\n",
        "    # Dataloader initialization for training, validation and test\n",
        "    train_path = os.path.join(extract_dir, 'EMOVO_aug', 'train')\n",
        "    val_path = os.path.join(extract_dir, 'EMOVO_aug', 'val')\n",
        "\n",
        "    train_dataset = dataset.EMOVO_Dataset(train_path, feature_extract=True, mfcc_np=False, device=device)\n",
        "    val_dataset = dataset.EMOVO_Dataset(val_path, feature_extract=True, mfcc_np=False, device=device)\n",
        "\n",
        "elif AUG == False:\n",
        "\n",
        "    train_path = os.path.join(extract_dir, 'EMOVO_split_MFCC', 'train')\n",
        "    val_path = os.path.join(extract_dir, 'EMOVO_split_MFCC', 'val')\n",
        "\n",
        "    train_dataset = dataset.EMOVO_Dataset(train_path, feature_extract=False, mfcc_np=True, device=device)\n",
        "    val_dataset = dataset.EMOVO_Dataset(val_path, feature_extract=False, mfcc_np=True, device=device)\n",
        "\n",
        "\n",
        "# Dataloader initialization\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Definition of the Categorical Cross Entropy Loss\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing = LABEL_SMOOTHING)\n",
        "\n",
        "# Definition of the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=LR_SCHEDULER, patience=5)\n",
        "\n",
        "train(\n",
        "    EPOCHS, \n",
        "    training_metrics_dict, \n",
        "    validation_metrics_dict, \n",
        "    train_dataloader, \n",
        "    val_dataloader, \n",
        "    model, \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    lr_scheduler, \n",
        "    cfg\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
