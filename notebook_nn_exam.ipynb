{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dIRawMyjYAz"
      },
      "source": [
        "⚠️Clone the repository to use all the functions needed by the main code⚠️\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvEJSRQzjVVO",
        "outputId": "621797ba-2595-461d-e6ec-8c898391b5dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are running locally!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    mode = 'colab'\n",
        "except:\n",
        "    mode = 'local'\n",
        "\n",
        "if mode == 'colab':\n",
        "    !git clone \"https://github.com/cybernetic-m/nn-project.git\"\n",
        "    !pip install hydra-core --upgrade convkan\n",
        "else:\n",
        "    print(\"You are running locally!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZNKzy8qbbu2"
      },
      "source": [
        "# IMPORT AND INITIALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dKakfnMRbKum"
      },
      "outputs": [],
      "source": [
        "# Import for config.yaml file\n",
        "from hydra import initialize, compose\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "if mode == 'colab':\n",
        "    sys.path.append('/content/nn-project/dataloader')\n",
        "    sys.path.append('/content/nn-project/model')\n",
        "    sys.path.append('/content/nn-project/module')\n",
        "    sys.path.append('/content/nn-project/training')\n",
        "    sys.path.append('/content/nn-project/testing')\n",
        "    from preprocessing import Preprocessing\n",
        "    import utils\n",
        "    import dataset\n",
        "    from ctim import CTIM\n",
        "    from train import *\n",
        "    from test import *\n",
        "\n",
        "\n",
        "if mode == 'local':\n",
        "    import dataloader.utils as utils\n",
        "    import dataloader.dataset as dataset\n",
        "    from dataloader.preprocessing import Preprocessing\n",
        "    from model.ctim import CTIM\n",
        "    from training.train import train as train\n",
        "    from testing.test import test as test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzpebiXBPJE-"
      },
      "source": [
        "Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X3f4K2m8PIrc"
      },
      "outputs": [],
      "source": [
        "# Set the seed\n",
        "seed = 46\n",
        "\n",
        "# Set seed for torch, numpy and random libraries\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Set the devide mode on GPU (if available CUDA for Nvidia and  MPS for Apple Silicon) or CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mV42Zq-UKCz"
      },
      "source": [
        "## Download and Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV_poPYiccs2",
        "outputId": "e50c5a1d-7044-4167-99c3-48ec2f05c711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already downloaded\n",
            "Dataset already unzipped\n"
          ]
        }
      ],
      "source": [
        "link_dataset = \"https://drive.google.com/file/d/1nzKBta2M3khw7Ql_S7atYg-H-bWDiOxr/view?usp=drive_link\"\n",
        "gdrive_link = \"https://drive.google.com/uc?export=download&id=\"\n",
        "\n",
        "if mode == 'colab':\n",
        "    destination_dir = \"/content/emovo.zip\"\n",
        "    extract_dir = '/content/dataset'\n",
        "    emovo_dir = '/content/dataset/EMOVO'\n",
        "    emovo_split_dir = '/content/dataset/EMOVO_split'\n",
        "elif mode == 'local':\n",
        "    destination_dir = \"./emovo.zip\"\n",
        "    extract_dir = \"./dataset\"\n",
        "    emovo_dir = \"./dataset/EMOVO\"\n",
        "    emovo_split_dir = './dataset/EMOVO_split'\n",
        "\n",
        "utils.download_dataset(link_dataset, destination_dir, gdrive_link, extract_dir)\n",
        "\n",
        "utils.dataset_split(emovo_dir, extract_dir, 0.7, 0.2, 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.dataset_split_mfcc('./EMOVO.npy', extract_dir, 0.7, 0.2, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrZ8n_tp2nfh"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBRzIeeY2nfh",
        "outputId": "b7a2bfe4-c0e0-40ab-94c7-f9a3afffa6d9"
      },
      "outputs": [],
      "source": [
        "preprocessing = Preprocessing(device=device)\n",
        "\n",
        "utils.augment_data(emovo_split_dir, extract_dir, preprocessing, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVRKvN26UUq9"
      },
      "source": [
        "## Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRn6VibgUXm9",
        "outputId": "491fc476-55ab-423a-f653-619cae3944dc"
      },
      "outputs": [],
      "source": [
        "train_path = os.path.join(extract_dir, 'EMOVO_split', 'train')\n",
        "test_path = os.path.join(extract_dir, 'EMOVO_split', 'test')\n",
        "val_path = os.path.join(extract_dir, 'EMOVO_split', 'val')\n",
        "\n",
        "train_dataset = dataset.EMOVO_Dataset(train_path, False, device=device)\n",
        "test_dataset = dataset.EMOVO_Dataset(test_path, False, device=device)\n",
        "val_dataset = dataset.EMOVO_Dataset(val_path, False, device=device)\n",
        "\n",
        "train_aug_path = os.path.join(extract_dir, 'EMOVO_aug', 'train')\n",
        "test_aug_path = os.path.join(extract_dir, 'EMOVO_aug', 'test')\n",
        "val_aug_path = os.path.join(extract_dir, 'EMOVO_aug', 'val')\n",
        "\n",
        "train_aug_dataset = dataset.EMOVO_Dataset(train_aug_path, device=device)\n",
        "test_aug_dataset = dataset.EMOVO_Dataset(test_aug_path, device=device)\n",
        "val_aug_dataset = dataset.EMOVO_Dataset(val_aug_path, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ9URMKkfQmU"
      },
      "source": [
        "Example of audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "mcblPPkeZw35",
        "outputId": "f79994e1-f311-4cb7-f112-de385323b3ae"
      },
      "outputs": [],
      "source": [
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "random_num = random.randint(1, train_dataset.__len__())\n",
        "data, label = train_dataset[random_num]\n",
        "\n",
        "print(\"Tensor of shape:\",data[0].shape, \"Sample Rate:\", data[1])\n",
        "print(\"Class:\", classes[label], \"\\n\")\n",
        "\n",
        "# Waveform\n",
        "# Compute the average of both channels to get a mono waveform\n",
        "mono_waveform = data[0].mean(dim=0)\n",
        "num_samples = mono_waveform.shape[0]\n",
        "sample_rate = data[1]\n",
        "time_axis = np.linspace(0, num_samples / sample_rate, num_samples)\n",
        "\n",
        "# Play the audio\n",
        "display(Audio(mono_waveform.cpu().numpy(), rate=sample_rate))\n",
        "\n",
        "# Plot the averaged (mono) waveform\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_axis, mono_waveform.cpu().numpy())\n",
        "plt.title('Waveform (Averaged Mono)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSzFkhBu2nfi"
      },
      "source": [
        "Example of augmented audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5XiV4x82nfi"
      },
      "outputs": [],
      "source": [
        "# TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnwkpxVjIDni"
      },
      "source": [
        "Data distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "q3Hs-83fIHPT",
        "outputId": "f64ac95c-b03e-4b4b-9156-c7e93f23e3b8"
      },
      "outputs": [],
      "source": [
        "train_counts = train_dataset.get_info()\n",
        "test_counts = test_dataset.get_info()\n",
        "val_counts = val_dataset.get_info()\n",
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(16, 4))\n",
        "\n",
        "ax[0].bar(classes, train_counts, color='limegreen')\n",
        "ax[0].set_title(\"Data distribution in Training Set\")\n",
        "ax[0].set_xlabel(\"Classes\")\n",
        "ax[0].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[0].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[1].bar(classes, test_counts, color='seagreen')\n",
        "ax[1].set_title(\"Data distribution in Test Set\")\n",
        "ax[1].set_xlabel(\"Classes\")\n",
        "ax[1].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[1].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[2].bar(classes, val_counts, color='olive')\n",
        "ax[2].set_title(\"Data distribution in Validation Set\")\n",
        "ax[2].set_xlabel(\"Classes\")\n",
        "ax[2].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[2].set_ylabel(\"Number of samples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzyjYYHp2nfi"
      },
      "source": [
        "Data augmented distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "WUqtdsOf2nfi",
        "outputId": "3d60a842-b1f0-41c5-f68d-d605dbfcbd14"
      },
      "outputs": [],
      "source": [
        "train_aug_counts = train_aug_dataset.get_info()\n",
        "test_aug_counts = test_aug_dataset.get_info()\n",
        "val_aug_counts = val_aug_dataset.get_info()\n",
        "classes = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(16, 4))\n",
        "\n",
        "ax[0].bar(classes, train_aug_counts, color='limegreen')\n",
        "ax[0].set_title(\"Data distribution in Training Set\")\n",
        "ax[0].set_xlabel(\"Classes\")\n",
        "ax[0].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[0].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[1].bar(classes, test_aug_counts, color='seagreen')\n",
        "ax[1].set_title(\"Data distribution in Test Set\")\n",
        "ax[1].set_xlabel(\"Classes\")\n",
        "ax[1].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[1].set_ylabel(\"Number of samples\")\n",
        "\n",
        "ax[2].bar(classes, val_aug_counts, color='olive')\n",
        "ax[2].set_title(\"Data distribution in Validation Set\")\n",
        "ax[2].set_xlabel(\"Classes\")\n",
        "ax[2].set_xticks(ticks=range(7), labels=classes)\n",
        "ax[2].set_ylabel(\"Number of samples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6u2yOd0iuRt"
      },
      "source": [
        "# HYDRA INITIALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK9-Zzs-iuRt",
        "outputId": "e32700b7-b64a-4601-cd21-6b343b4a1365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hydra now initialized!\n"
          ]
        }
      ],
      "source": [
        "# Check if Hydra is initialized\n",
        "if GlobalHydra().is_initialized():\n",
        "    # Clear the Hydra instance if it is initialized\n",
        "    GlobalHydra.instance().clear()\n",
        "    print(\"Hydra instance was initialized and has been cleared.\")\n",
        "else:\n",
        "    # Initialize\n",
        "    print(\"Hydra now initialized!\")\n",
        "\n",
        "# Initialization and Load configuration\n",
        "if mode == 'local':\n",
        "  initialize(config_path=\"./conf\", job_name=\"notebook_nn_exam\", version_base=None)\n",
        "  cfg = compose(config_name=\"config\")\n",
        "\n",
        "elif mode == 'colab':\n",
        "  initialize(config_path=\"./nn-project/conf\", job_name=\"notebook_nn_exam\", version_base=None)\n",
        "  cfg = compose(config_name=\"config\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vn5O9hp_iuRt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------+------------+\n",
            "|                       Modules                       | Parameters |\n",
            "+-----------------------------------------------------+------------+\n",
            "|               ctim_net.weightsdyn_fun               |     8      |\n",
            "|             ctim_net.conv_forward.weight            |    1521    |\n",
            "|              ctim_net.conv_forward.bias             |     39     |\n",
            "|             ctim_net.conv_reverse.weight            |    1521    |\n",
            "|              ctim_net.conv_reverse.bias             |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.0.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.0.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.0.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.0.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.0.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.0.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.0.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.0.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.1.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.1.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.1.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.1.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.1.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.1.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.1.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.1.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.2.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.2.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.2.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.2.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.2.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.2.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.2.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.2.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.3.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.3.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.3.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.3.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.3.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.3.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.3.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.3.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.4.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.4.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.4.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.4.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.4.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.4.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.4.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.4.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.5.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.5.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.5.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.5.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.5.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.5.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.5.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.5.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.6.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.6.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.6.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.6.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.6.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.6.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.6.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.6.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.7.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.7.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_forward.7.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_forward.7.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.7.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.7.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_forward.7.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_forward.7.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.0.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.0.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.0.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.0.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.0.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.0.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.0.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.0.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.1.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.1.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.1.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.1.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.1.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.1.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.1.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.1.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.2.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.2.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.2.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.2.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.2.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.2.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.2.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.2.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.3.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.3.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.3.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.3.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.3.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.3.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.3.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.3.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.4.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.4.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.4.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.4.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.4.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.4.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.4.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.4.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.5.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.5.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.5.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.5.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.5.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.5.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.5.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.5.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.6.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.6.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.6.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.6.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.6.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.6.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.6.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.6.batch_norm2.bias  |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.7.conv1.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.7.conv1.bias     |     39     |\n",
            "|    ctim_net.TempAw_Blocks_reverse.7.conv2.weight    |    3042    |\n",
            "|     ctim_net.TempAw_Blocks_reverse.7.conv2.bias     |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.7.batch_norm1.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.7.batch_norm1.bias  |     39     |\n",
            "| ctim_net.TempAw_Blocks_reverse.7.batch_norm2.weight |     39     |\n",
            "|  ctim_net.TempAw_Blocks_reverse.7.batch_norm2.bias  |     39     |\n",
            "|                  classifier.weight                  |    273     |\n",
            "|                   classifier.bias                   |     7      |\n",
            "+-----------------------------------------------------+------------+\n",
            "Total Trainable Params: 104496\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "104496"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the hyperparameters of the model\n",
        "DROPOUT_RATE = cfg.model.dropout_rate\n",
        "KERNEL_SIZE = cfg.model.kernel_size\n",
        "N_TAB = cfg.model.n_temporal_aware_block\n",
        "N_FILTER = cfg.model.n_filter\n",
        "NUM_FEATURES = cfg.model.num_features\n",
        "CK = cfg.model.ck\n",
        "USE_KAN = cfg.model.use_kan\n",
        "OMEGA_0 = cfg.model.omega_0\n",
        "IS_SIREN = cfg.model.is_siren\n",
        "\n",
        "model = CTIM(\n",
        "    kernel_size=KERNEL_SIZE,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    n_temporal_aware_block=N_TAB,\n",
        "    n_filter=N_FILTER,\n",
        "    in_channels=39,\n",
        "    ck=CK,\n",
        "    num_features=NUM_FEATURES,\n",
        "    num_classes = 7,\n",
        "    use_kan = False,\n",
        "    omega_0=OMEGA_0,\n",
        "    is_siren=IS_SIREN,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUdCPiRZiuRu"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = os.path.join(extract_dir, 'EMOVO_split_MFCC', 'train')\n",
        "test_path = os.path.join(extract_dir, 'EMOVO_split_MFCC', 'test')\n",
        "val_path = os.path.join(extract_dir, 'EMOVO_split_MFCC', 'val')\n",
        "\n",
        "\n",
        "# \n",
        "train_dataset = dataset.EMOVO_Dataset(train_path, feature_extract=False, mfcc_np=True, device=device)\n",
        "test_dataset = dataset.EMOVO_Dataset(test_path, feature_extract=False, mfcc_np=True, device=device)\n",
        "val_dataset = dataset.EMOVO_Dataset(val_path, feature_extract=False, mfcc_np=True, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EmPUS-iBiuRu",
        "outputId": "58030685-a642-4cea-ff80-09af8c680bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/500:\n",
            "TRAIN:\n",
            "accuracy: 13.18, precision: 7.54, recall: 13.33, f1-score: 9.61\n",
            "VALIDATION:\n",
            "accuracy: 20.00, precision: 29.08, recall: 20.83, f1-score: 15.49\n",
            "LOSS train 13.287283208635118 valid 3.4637120564778647\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:28/model.pt\n",
            "EPOCH 2/500:\n",
            "TRAIN:\n",
            "accuracy: 19.40, precision: 18.33, recall: 19.32, f1-score: 17.03\n",
            "VALIDATION:\n",
            "accuracy: 20.74, precision: 13.42, recall: 20.04, f1-score: 10.71\n",
            "LOSS train 4.366836309432983 valid 4.680892149607341\n",
            "EPOCH 3/500:\n",
            "TRAIN:\n",
            "accuracy: 20.15, precision: 31.32, recall: 20.23, f1-score: 20.19\n",
            "VALIDATION:\n",
            "accuracy: 21.48, precision: 27.48, recall: 22.66, f1-score: 14.69\n",
            "LOSS train 3.3371951315138073 valid 2.773470481236776\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:33/model.pt\n",
            "EPOCH 4/500:\n",
            "TRAIN:\n",
            "accuracy: 29.19, precision: 28.47, recall: 29.36, f1-score: 27.10\n",
            "VALIDATION:\n",
            "accuracy: 31.85, precision: 25.83, recall: 32.16, f1-score: 26.83\n",
            "LOSS train 2.6734792391459146 valid 2.486367623011271\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:37/model.pt\n",
            "EPOCH 5/500:\n",
            "TRAIN:\n",
            "accuracy: 35.22, precision: 35.42, recall: 35.37, f1-score: 34.96\n",
            "VALIDATION:\n",
            "accuracy: 33.33, precision: 34.55, recall: 34.39, f1-score: 30.27\n",
            "LOSS train 2.129779961374071 valid 2.0458397467931113\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:40/model.pt\n",
            "EPOCH 6/500:\n",
            "TRAIN:\n",
            "accuracy: 36.35, precision: 38.75, recall: 36.34, f1-score: 36.87\n",
            "VALIDATION:\n",
            "accuracy: 46.67, precision: 55.16, recall: 46.53, f1-score: 44.87\n",
            "LOSS train 2.0112567212846546 valid 1.4428326686223347\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:43/model.pt\n",
            "EPOCH 7/500:\n",
            "TRAIN:\n",
            "accuracy: 36.16, precision: 36.35, recall: 36.35, f1-score: 35.42\n",
            "VALIDATION:\n",
            "accuracy: 42.96, precision: 57.95, recall: 42.80, f1-score: 42.15\n",
            "LOSS train 1.9500902096430461 valid 1.6292719443639119\n",
            "EPOCH 8/500:\n",
            "TRAIN:\n",
            "accuracy: 39.55, precision: 43.74, recall: 39.56, f1-score: 39.91\n",
            "VALIDATION:\n",
            "accuracy: 58.52, precision: 68.40, recall: 59.02, f1-score: 57.48\n",
            "LOSS train 1.8072348833084106 valid 1.280343770980835\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:48/model.pt\n",
            "EPOCH 9/500:\n",
            "TRAIN:\n",
            "accuracy: 40.11, precision: 41.41, recall: 40.31, f1-score: 39.34\n",
            "VALIDATION:\n",
            "accuracy: 42.96, precision: 69.40, recall: 42.63, f1-score: 39.67\n",
            "LOSS train 1.8006009525722928 valid 1.6990065972010295\n",
            "EPOCH 10/500:\n",
            "TRAIN:\n",
            "accuracy: 45.76, precision: 48.65, recall: 45.70, f1-score: 45.82\n",
            "VALIDATION:\n",
            "accuracy: 42.22, precision: 59.56, recall: 42.06, f1-score: 40.38\n",
            "LOSS train 1.6866333882013957 valid 1.985764503479004\n",
            "EPOCH 11/500:\n",
            "TRAIN:\n",
            "accuracy: 45.95, precision: 47.39, recall: 46.19, f1-score: 45.90\n",
            "VALIDATION:\n",
            "accuracy: 60.74, precision: 69.66, recall: 60.52, f1-score: 60.20\n",
            "LOSS train 1.6364321046405368 valid 1.2630359331766765\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:06:56/model.pt\n",
            "EPOCH 12/500:\n",
            "TRAIN:\n",
            "accuracy: 47.46, precision: 48.42, recall: 47.55, f1-score: 47.58\n",
            "VALIDATION:\n",
            "accuracy: 55.56, precision: 68.21, recall: 56.09, f1-score: 52.00\n",
            "LOSS train 1.5459171798494127 valid 1.3844703038533528\n",
            "EPOCH 13/500:\n",
            "TRAIN:\n",
            "accuracy: 51.41, precision: 51.00, recall: 51.62, f1-score: 51.17\n",
            "VALIDATION:\n",
            "accuracy: 58.52, precision: 63.46, recall: 58.94, f1-score: 58.08\n",
            "LOSS train 1.4569712214999728 valid 1.3370303710301716\n",
            "EPOCH 14/500:\n",
            "TRAIN:\n",
            "accuracy: 50.66, precision: 51.25, recall: 50.72, f1-score: 50.47\n",
            "VALIDATION:\n",
            "accuracy: 63.70, precision: 73.63, recall: 63.48, f1-score: 62.11\n",
            "LOSS train 1.5088752905527751 valid 1.289078712463379\n",
            "EPOCH 15/500:\n",
            "TRAIN:\n",
            "accuracy: 51.79, precision: 54.22, recall: 51.79, f1-score: 52.19\n",
            "VALIDATION:\n",
            "accuracy: 68.15, precision: 75.42, recall: 68.22, f1-score: 66.49\n",
            "LOSS train 1.5191060569551256 valid 1.1733254194259644\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:08/model.pt\n",
            "EPOCH 16/500:\n",
            "TRAIN:\n",
            "accuracy: 54.99, precision: 55.61, recall: 55.16, f1-score: 54.93\n",
            "VALIDATION:\n",
            "accuracy: 65.19, precision: 81.24, recall: 65.13, f1-score: 65.70\n",
            "LOSS train 1.3927687406539917 valid 1.1136085987091064\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:12/model.pt\n",
            "EPOCH 17/500:\n",
            "TRAIN:\n",
            "accuracy: 56.50, precision: 57.15, recall: 56.59, f1-score: 56.08\n",
            "VALIDATION:\n",
            "accuracy: 68.15, precision: 79.21, recall: 68.07, f1-score: 69.96\n",
            "LOSS train 1.4163200987709894 valid 1.4032524824142456\n",
            "EPOCH 18/500:\n",
            "TRAIN:\n",
            "accuracy: 61.02, precision: 62.10, recall: 61.08, f1-score: 61.21\n",
            "VALIDATION:\n",
            "accuracy: 71.11, precision: 77.93, recall: 70.84, f1-score: 71.02\n",
            "LOSS train 1.3503956927193537 valid 1.0327130357424419\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:17/model.pt\n",
            "EPOCH 19/500:\n",
            "TRAIN:\n",
            "accuracy: 56.31, precision: 58.08, recall: 56.43, f1-score: 56.60\n",
            "VALIDATION:\n",
            "accuracy: 52.59, precision: 55.73, recall: 53.38, f1-score: 47.18\n",
            "LOSS train 1.3737481435139973 valid 1.74018394947052\n",
            "EPOCH 20/500:\n",
            "TRAIN:\n",
            "accuracy: 58.57, precision: 60.37, recall: 58.66, f1-score: 58.81\n",
            "VALIDATION:\n",
            "accuracy: 71.85, precision: 79.26, recall: 71.71, f1-score: 72.10\n",
            "LOSS train 1.3136290576722887 valid 1.0740430355072021\n",
            "EPOCH 21/500:\n",
            "TRAIN:\n",
            "accuracy: 61.96, precision: 63.42, recall: 61.96, f1-score: 61.89\n",
            "VALIDATION:\n",
            "accuracy: 75.56, precision: 77.91, recall: 75.68, f1-score: 75.14\n",
            "LOSS train 1.322627239757114 valid 1.102403958638509\n",
            "EPOCH 22/500:\n",
            "TRAIN:\n",
            "accuracy: 63.65, precision: 65.50, recall: 63.84, f1-score: 63.54\n",
            "VALIDATION:\n",
            "accuracy: 68.89, precision: 79.42, recall: 69.06, f1-score: 68.73\n",
            "LOSS train 1.2566088570488825 valid 1.2124160528182983\n",
            "EPOCH 23/500:\n",
            "TRAIN:\n",
            "accuracy: 63.28, precision: 63.59, recall: 63.34, f1-score: 63.20\n",
            "VALIDATION:\n",
            "accuracy: 70.37, precision: 78.50, recall: 70.12, f1-score: 66.99\n",
            "LOSS train 1.304449650976393 valid 1.1376006205876668\n",
            "EPOCH 24/500:\n",
            "TRAIN:\n",
            "accuracy: 61.39, precision: 64.65, recall: 61.45, f1-score: 61.99\n",
            "VALIDATION:\n",
            "accuracy: 69.63, precision: 79.23, recall: 69.97, f1-score: 68.64\n",
            "LOSS train 1.2328305906719632 valid 1.0756832758585613\n",
            "EPOCH 25/500:\n",
            "TRAIN:\n",
            "accuracy: 68.17, precision: 71.87, recall: 68.39, f1-score: 67.25\n",
            "VALIDATION:\n",
            "accuracy: 82.96, precision: 86.38, recall: 83.10, f1-score: 83.42\n",
            "LOSS train 1.175399402777354 valid 0.9143786231676737\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:35/model.pt\n",
            "EPOCH 26/500:\n",
            "TRAIN:\n",
            "accuracy: 70.62, precision: 71.41, recall: 70.69, f1-score: 70.79\n",
            "VALIDATION:\n",
            "accuracy: 80.74, precision: 85.31, recall: 80.91, f1-score: 80.44\n",
            "LOSS train 1.113465044233534 valid 0.986210823059082\n",
            "EPOCH 27/500:\n",
            "TRAIN:\n",
            "accuracy: 68.17, precision: 69.07, recall: 68.19, f1-score: 68.45\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.83, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 1.1662934753629897 valid 0.867255171140035\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:41/model.pt\n",
            "EPOCH 28/500:\n",
            "TRAIN:\n",
            "accuracy: 71.37, precision: 71.45, recall: 71.53, f1-score: 71.21\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 89.10, recall: 88.85, f1-score: 88.85\n",
            "LOSS train 1.1115598016315036 valid 0.8543879787127177\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:44/model.pt\n",
            "EPOCH 29/500:\n",
            "TRAIN:\n",
            "accuracy: 68.74, precision: 69.19, recall: 68.80, f1-score: 68.86\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 89.73, recall: 88.77, f1-score: 88.86\n",
            "LOSS train 1.0996378130382962 valid 0.9071610967318217\n",
            "EPOCH 30/500:\n",
            "TRAIN:\n",
            "accuracy: 69.30, precision: 70.42, recall: 69.34, f1-score: 69.62\n",
            "VALIDATION:\n",
            "accuracy: 88.15, precision: 89.07, recall: 87.98, f1-score: 88.12\n",
            "LOSS train 1.1292304595311482 valid 0.849574605623881\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:49/model.pt\n",
            "EPOCH 31/500:\n",
            "TRAIN:\n",
            "accuracy: 72.88, precision: 73.41, recall: 72.98, f1-score: 73.09\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.90, recall: 89.64, f1-score: 89.87\n",
            "LOSS train 1.0818709399965074 valid 0.8758846124013265\n",
            "EPOCH 32/500:\n",
            "TRAIN:\n",
            "accuracy: 69.87, precision: 70.22, recall: 69.97, f1-score: 69.91\n",
            "VALIDATION:\n",
            "accuracy: 88.15, precision: 90.41, recall: 88.02, f1-score: 88.40\n",
            "LOSS train 1.1059620512856378 valid 0.8150213162104288\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:07:54/model.pt\n",
            "EPOCH 33/500:\n",
            "TRAIN:\n",
            "accuracy: 71.37, precision: 71.74, recall: 71.38, f1-score: 71.40\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.42, recall: 89.64, f1-score: 89.68\n",
            "LOSS train 1.0995033118459914 valid 0.9687520464261373\n",
            "EPOCH 34/500:\n",
            "TRAIN:\n",
            "accuracy: 74.01, precision: 74.28, recall: 74.10, f1-score: 74.16\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.39, recall: 89.57, f1-score: 89.53\n",
            "LOSS train 1.0839952958954706 valid 0.8534653981526693\n",
            "EPOCH 35/500:\n",
            "TRAIN:\n",
            "accuracy: 73.07, precision: 73.26, recall: 73.20, f1-score: 73.01\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 89.89, recall: 88.77, f1-score: 88.91\n",
            "LOSS train 1.0865752432081435 valid 0.8558142979939779\n",
            "EPOCH 36/500:\n",
            "TRAIN:\n",
            "accuracy: 70.62, precision: 71.31, recall: 70.72, f1-score: 70.60\n",
            "VALIDATION:\n",
            "accuracy: 88.15, precision: 89.14, recall: 88.06, f1-score: 88.18\n",
            "LOSS train 1.0979709227879841 valid 0.8652940988540649\n",
            "EPOCH 37/500:\n",
            "TRAIN:\n",
            "accuracy: 73.45, precision: 74.02, recall: 73.48, f1-score: 73.55\n",
            "VALIDATION:\n",
            "accuracy: 88.15, precision: 88.95, recall: 88.06, f1-score: 88.19\n",
            "LOSS train 1.0635788904296026 valid 0.9052555561065674\n",
            "EPOCH 38/500:\n",
            "TRAIN:\n",
            "accuracy: 70.06, precision: 70.35, recall: 70.18, f1-score: 69.99\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.089496824476454 valid 0.7664540807406107\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:08:10/model.pt\n",
            "EPOCH 39/500:\n",
            "TRAIN:\n",
            "accuracy: 73.63, precision: 73.88, recall: 73.71, f1-score: 73.64\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.01, recall: 88.85, f1-score: 89.07\n",
            "LOSS train 1.094250241915385 valid 0.8088027040163676\n",
            "EPOCH 40/500:\n",
            "TRAIN:\n",
            "accuracy: 72.32, precision: 73.00, recall: 72.39, f1-score: 72.55\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.17, recall: 90.44, f1-score: 90.55\n",
            "LOSS train 1.086933970451355 valid 0.8445569276809692\n",
            "EPOCH 41/500:\n",
            "TRAIN:\n",
            "accuracy: 73.63, precision: 73.70, recall: 73.73, f1-score: 73.69\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.82, recall: 89.53, f1-score: 89.67\n",
            "LOSS train 1.0527747008535597 valid 0.8248354991277059\n",
            "EPOCH 42/500:\n",
            "TRAIN:\n",
            "accuracy: 72.50, precision: 74.39, recall: 72.54, f1-score: 72.97\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.59, recall: 89.57, f1-score: 89.58\n",
            "LOSS train 1.0537872976726956 valid 0.7790844241778055\n",
            "EPOCH 43/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 75.01, recall: 74.63, f1-score: 74.63\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.19, recall: 89.57, f1-score: 89.48\n",
            "LOSS train 1.0538407166798909 valid 0.7812028527259827\n",
            "EPOCH 44/500:\n",
            "TRAIN:\n",
            "accuracy: 71.37, precision: 71.37, recall: 71.53, f1-score: 71.29\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.82, recall: 89.52, f1-score: 89.62\n",
            "LOSS train 1.056091354952918 valid 0.8954604466756185\n",
            "EPOCH 45/500:\n",
            "TRAIN:\n",
            "accuracy: 76.08, precision: 76.43, recall: 76.15, f1-score: 76.20\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.52, recall: 89.52, f1-score: 89.59\n",
            "LOSS train 1.0196808642811246 valid 0.7783648570378622\n",
            "EPOCH 46/500:\n",
            "TRAIN:\n",
            "accuracy: 74.20, precision: 74.59, recall: 74.26, f1-score: 74.28\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 89.89, recall: 88.77, f1-score: 88.91\n",
            "LOSS train 1.0200014180607266 valid 0.7888648509979248\n",
            "EPOCH 47/500:\n",
            "TRAIN:\n",
            "accuracy: 77.02, precision: 77.37, recall: 77.12, f1-score: 77.16\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.44, recall: 89.57, f1-score: 89.60\n",
            "LOSS train 1.014768832259708 valid 0.7572351892789205\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:08:34/model.pt\n",
            "EPOCH 48/500:\n",
            "TRAIN:\n",
            "accuracy: 74.20, precision: 74.51, recall: 74.24, f1-score: 74.14\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0374763011932373 valid 0.8646896084149679\n",
            "EPOCH 49/500:\n",
            "TRAIN:\n",
            "accuracy: 74.20, precision: 74.39, recall: 74.27, f1-score: 74.25\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0533519321017795 valid 0.7662587364514669\n",
            "EPOCH 50/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 74.87, recall: 74.63, f1-score: 74.58\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.033876982000139 valid 0.810591459274292\n",
            "EPOCH 51/500:\n",
            "TRAIN:\n",
            "accuracy: 73.45, precision: 73.83, recall: 73.53, f1-score: 73.56\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.36, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0537613497840033 valid 0.9089408119519552\n",
            "EPOCH 52/500:\n",
            "TRAIN:\n",
            "accuracy: 76.08, precision: 76.27, recall: 76.11, f1-score: 76.12\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.26, recall: 90.36, f1-score: 90.47\n",
            "LOSS train 1.018231623702579 valid 0.7872781753540039\n",
            "EPOCH 53/500:\n",
            "TRAIN:\n",
            "accuracy: 76.27, precision: 76.25, recall: 76.41, f1-score: 76.28\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.26, recall: 90.36, f1-score: 90.47\n",
            "LOSS train 1.0493797593646579 valid 0.8231145540873209\n",
            "EPOCH 54/500:\n",
            "TRAIN:\n",
            "accuracy: 72.32, precision: 72.63, recall: 72.38, f1-score: 72.41\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0541125271055434 valid 0.8108992377916971\n",
            "EPOCH 55/500:\n",
            "TRAIN:\n",
            "accuracy: 74.20, precision: 74.41, recall: 74.23, f1-score: 74.17\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 0.9952349993917677 valid 0.8499831159909567\n",
            "EPOCH 56/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 74.92, recall: 75.05, f1-score: 74.88\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.44, recall: 89.57, f1-score: 89.60\n",
            "LOSS train 1.0309576524628534 valid 0.7895506024360657\n",
            "EPOCH 57/500:\n",
            "TRAIN:\n",
            "accuracy: 74.39, precision: 74.42, recall: 74.44, f1-score: 74.35\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.26, recall: 90.36, f1-score: 90.47\n",
            "LOSS train 1.0471317834324307 valid 0.8262882828712463\n",
            "EPOCH 58/500:\n",
            "TRAIN:\n",
            "accuracy: 76.08, precision: 76.41, recall: 76.12, f1-score: 76.13\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0342941946453519 valid 0.8062667449315389\n",
            "EPOCH 59/500:\n",
            "TRAIN:\n",
            "accuracy: 76.27, precision: 76.24, recall: 76.36, f1-score: 76.27\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.68, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 1.0269458691279094 valid 0.766595701376597\n",
            "EPOCH 60/500:\n",
            "TRAIN:\n",
            "accuracy: 75.71, precision: 76.19, recall: 75.72, f1-score: 75.76\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.58, recall: 89.57, f1-score: 89.62\n",
            "LOSS train 1.0376654598448012 valid 0.9409657915433248\n",
            "EPOCH 61/500:\n",
            "TRAIN:\n",
            "accuracy: 77.02, precision: 77.60, recall: 77.12, f1-score: 77.12\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0423603190316095 valid 0.7778605024019877\n",
            "EPOCH 62/500:\n",
            "TRAIN:\n",
            "accuracy: 79.10, precision: 79.17, recall: 79.16, f1-score: 79.04\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.52, recall: 89.57, f1-score: 89.58\n",
            "LOSS train 0.9907115035586886 valid 0.8615927298863729\n",
            "EPOCH 63/500:\n",
            "TRAIN:\n",
            "accuracy: 75.71, precision: 76.01, recall: 75.79, f1-score: 75.81\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.31, recall: 90.28, f1-score: 90.33\n",
            "LOSS train 1.007725887828403 valid 0.7858308553695679\n",
            "EPOCH 64/500:\n",
            "TRAIN:\n",
            "accuracy: 74.20, precision: 74.34, recall: 74.26, f1-score: 74.23\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 89.89, recall: 88.77, f1-score: 88.91\n",
            "LOSS train 1.0701744622654386 valid 0.7939109007517496\n",
            "EPOCH 65/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 75.36, recall: 75.03, f1-score: 75.05\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 1.004061758518219 valid 0.7547417481740316\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:09:20/model.pt\n",
            "EPOCH 66/500:\n",
            "TRAIN:\n",
            "accuracy: 76.08, precision: 76.42, recall: 76.14, f1-score: 76.22\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 0.9950179987483554 valid 0.873975912729899\n",
            "EPOCH 67/500:\n",
            "TRAIN:\n",
            "accuracy: 76.65, precision: 76.99, recall: 76.69, f1-score: 76.77\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0586746136347454 valid 0.8171014984448751\n",
            "EPOCH 68/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 75.18, recall: 75.06, f1-score: 75.03\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.68, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 0.990074892838796 valid 0.7879570921262106\n",
            "EPOCH 69/500:\n",
            "TRAIN:\n",
            "accuracy: 75.71, precision: 75.82, recall: 75.75, f1-score: 75.76\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.57, recall: 90.20, f1-score: 90.38\n",
            "LOSS train 1.0260770718256633 valid 0.799056609471639\n",
            "EPOCH 70/500:\n",
            "TRAIN:\n",
            "accuracy: 76.65, precision: 76.83, recall: 76.68, f1-score: 76.73\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.026609930727217 valid 0.7976086934407552\n",
            "EPOCH 71/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 74.73, recall: 74.63, f1-score: 74.56\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0533585084809198 valid 0.8200132250785828\n",
            "EPOCH 72/500:\n",
            "TRAIN:\n",
            "accuracy: 78.72, precision: 78.82, recall: 78.77, f1-score: 78.74\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.23\n",
            "LOSS train 1.0071645047929552 valid 0.8404418627421061\n",
            "EPOCH 73/500:\n",
            "TRAIN:\n",
            "accuracy: 75.33, precision: 75.46, recall: 75.40, f1-score: 75.37\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0158074895540874 valid 0.8407657146453857\n",
            "EPOCH 74/500:\n",
            "TRAIN:\n",
            "accuracy: 77.40, precision: 77.51, recall: 77.48, f1-score: 77.47\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0161129434903462 valid 0.8030487497647604\n",
            "EPOCH 75/500:\n",
            "TRAIN:\n",
            "accuracy: 75.33, precision: 75.64, recall: 75.35, f1-score: 75.39\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0142044756147597 valid 0.7994357546170553\n",
            "EPOCH 76/500:\n",
            "TRAIN:\n",
            "accuracy: 75.14, precision: 75.25, recall: 75.22, f1-score: 75.07\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.036325454711914 valid 0.7712072332700094\n",
            "EPOCH 77/500:\n",
            "TRAIN:\n",
            "accuracy: 75.89, precision: 76.10, recall: 75.96, f1-score: 75.98\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0177792178259955 valid 0.857390562693278\n",
            "EPOCH 78/500:\n",
            "TRAIN:\n",
            "accuracy: 74.76, precision: 74.94, recall: 74.83, f1-score: 74.82\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0246509710947673 valid 0.8374943335851034\n",
            "EPOCH 79/500:\n",
            "TRAIN:\n",
            "accuracy: 77.40, precision: 77.53, recall: 77.47, f1-score: 77.44\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 0.9914941125445895 valid 0.8258227308591207\n",
            "EPOCH 80/500:\n",
            "TRAIN:\n",
            "accuracy: 78.53, precision: 78.76, recall: 78.65, f1-score: 78.60\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0291820300949945 valid 0.7970851063728333\n",
            "EPOCH 81/500:\n",
            "TRAIN:\n",
            "accuracy: 75.71, precision: 76.12, recall: 75.73, f1-score: 75.83\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0049411522017584 valid 0.8413664102554321\n",
            "EPOCH 82/500:\n",
            "TRAIN:\n",
            "accuracy: 74.01, precision: 74.34, recall: 74.05, f1-score: 74.03\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0305404000812106 valid 0.7806934515635172\n",
            "EPOCH 83/500:\n",
            "TRAIN:\n",
            "accuracy: 74.76, precision: 74.87, recall: 74.82, f1-score: 74.73\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.57, recall: 90.20, f1-score: 90.36\n",
            "LOSS train 1.0381940404574077 valid 0.8067400455474854\n",
            "EPOCH 84/500:\n",
            "TRAIN:\n",
            "accuracy: 73.63, precision: 73.83, recall: 73.69, f1-score: 73.72\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.044155153963301 valid 0.8256697257359823\n",
            "EPOCH 85/500:\n",
            "TRAIN:\n",
            "accuracy: 75.33, precision: 75.56, recall: 75.41, f1-score: 75.36\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 1.0351104338963826 valid 0.7620664636294047\n",
            "EPOCH 86/500:\n",
            "TRAIN:\n",
            "accuracy: 74.76, precision: 75.04, recall: 74.87, f1-score: 74.83\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.21\n",
            "LOSS train 1.0107810828420851 valid 0.9086113373438517\n",
            "EPOCH 87/500:\n",
            "TRAIN:\n",
            "accuracy: 76.46, precision: 76.62, recall: 76.54, f1-score: 76.52\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0279524127642314 valid 0.7549385031064352\n",
            "EPOCH 88/500:\n",
            "TRAIN:\n",
            "accuracy: 75.52, precision: 75.62, recall: 75.60, f1-score: 75.53\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.44, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.003636399904887 valid 0.756894568602244\n",
            "EPOCH 89/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 75.13, recall: 74.60, f1-score: 74.75\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0532980230119493 valid 0.8118491371472677\n",
            "EPOCH 90/500:\n",
            "TRAIN:\n",
            "accuracy: 77.78, precision: 77.82, recall: 77.84, f1-score: 77.70\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 0.9691162440511916 valid 0.8886694113413492\n",
            "EPOCH 91/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 75.20, recall: 74.96, f1-score: 75.01\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0433155828052096 valid 0.8525562286376953\n",
            "EPOCH 92/500:\n",
            "TRAIN:\n",
            "accuracy: 75.52, precision: 75.54, recall: 75.60, f1-score: 75.43\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0328187081548903 valid 0.7837929725646973\n",
            "EPOCH 93/500:\n",
            "TRAIN:\n",
            "accuracy: 75.14, precision: 75.31, recall: 75.20, f1-score: 75.15\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0199362768067255 valid 0.811915655930837\n",
            "EPOCH 94/500:\n",
            "TRAIN:\n",
            "accuracy: 70.81, precision: 70.92, recall: 70.85, f1-score: 70.83\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0734018484751384 valid 0.7939288020133972\n",
            "EPOCH 95/500:\n",
            "TRAIN:\n",
            "accuracy: 74.20, precision: 74.44, recall: 74.28, f1-score: 74.28\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.047924366262224 valid 0.7704641421635946\n",
            "EPOCH 96/500:\n",
            "TRAIN:\n",
            "accuracy: 76.08, precision: 76.03, recall: 76.21, f1-score: 76.04\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 1.0399132635858324 valid 0.8111027081807455\n",
            "EPOCH 97/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 75.19, recall: 75.07, f1-score: 75.01\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.44, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0308762854999967 valid 0.7669190168380737\n",
            "EPOCH 98/500:\n",
            "TRAIN:\n",
            "accuracy: 72.50, precision: 72.68, recall: 72.57, f1-score: 72.55\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0422839323679607 valid 0.8222194314002991\n",
            "EPOCH 99/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 74.75, recall: 74.63, f1-score: 74.60\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.44, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0442807740635343 valid 0.7881907025973002\n",
            "EPOCH 100/500:\n",
            "TRAIN:\n",
            "accuracy: 73.82, precision: 73.99, recall: 73.86, f1-score: 73.84\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.095762636926439 valid 0.7960278193155924\n",
            "EPOCH 101/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 75.14, recall: 75.01, f1-score: 75.06\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.23\n",
            "LOSS train 1.0690226025051541 valid 0.7713876763979594\n",
            "EPOCH 102/500:\n",
            "TRAIN:\n",
            "accuracy: 76.65, precision: 76.75, recall: 76.74, f1-score: 76.67\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.21\n",
            "LOSS train 1.0010796917809381 valid 0.7729543050130209\n",
            "EPOCH 103/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 74.60, recall: 74.71, f1-score: 74.49\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.21\n",
            "LOSS train 1.0252624683909946 valid 0.7959270477294922\n",
            "EPOCH 104/500:\n",
            "TRAIN:\n",
            "accuracy: 79.28, precision: 79.97, recall: 79.33, f1-score: 79.48\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 0.968667831685808 valid 0.7738435467084249\n",
            "EPOCH 105/500:\n",
            "TRAIN:\n",
            "accuracy: 77.02, precision: 77.10, recall: 77.10, f1-score: 76.93\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.018031120300293 valid 0.7742211023966471\n",
            "EPOCH 106/500:\n",
            "TRAIN:\n",
            "accuracy: 76.46, precision: 76.71, recall: 76.52, f1-score: 76.56\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0094602439138625 valid 0.8022982676823934\n",
            "EPOCH 107/500:\n",
            "TRAIN:\n",
            "accuracy: 75.52, precision: 75.63, recall: 75.58, f1-score: 75.56\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 1.0110094547271729 valid 0.7734529972076416\n",
            "EPOCH 108/500:\n",
            "TRAIN:\n",
            "accuracy: 71.94, precision: 72.18, recall: 71.99, f1-score: 71.99\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0970001353157892 valid 0.7881220181783041\n",
            "EPOCH 109/500:\n",
            "TRAIN:\n",
            "accuracy: 78.34, precision: 78.44, recall: 78.44, f1-score: 78.34\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.45, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.004030664761861 valid 0.8451486627260844\n",
            "EPOCH 110/500:\n",
            "TRAIN:\n",
            "accuracy: 75.33, precision: 75.36, recall: 75.46, f1-score: 75.22\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.78, recall: 89.49, f1-score: 89.63\n",
            "LOSS train 1.0375860929489136 valid 0.8004132111867269\n",
            "EPOCH 111/500:\n",
            "TRAIN:\n",
            "accuracy: 76.08, precision: 76.15, recall: 76.14, f1-score: 76.11\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.21\n",
            "LOSS train 1.0615121788448758 valid 0.8514180978139242\n",
            "EPOCH 112/500:\n",
            "TRAIN:\n",
            "accuracy: 77.97, precision: 78.09, recall: 78.07, f1-score: 78.02\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 0.9899591075049506 valid 0.747853418191274\n",
            "saved: /Users/cyber_m/Desktop/Neural Network/nn-project/training/results/TIM2024-10-03_17:11:16/model.pt\n",
            "EPOCH 113/500:\n",
            "TRAIN:\n",
            "accuracy: 77.02, precision: 77.11, recall: 77.14, f1-score: 76.98\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0153714815775554 valid 0.7929883400599161\n",
            "EPOCH 114/500:\n",
            "TRAIN:\n",
            "accuracy: 77.78, precision: 77.82, recall: 77.86, f1-score: 77.78\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.78, recall: 89.49, f1-score: 89.63\n",
            "LOSS train 1.011455840534634 valid 0.8240564465522766\n",
            "EPOCH 115/500:\n",
            "TRAIN:\n",
            "accuracy: 79.28, precision: 79.47, recall: 79.36, f1-score: 79.38\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.21\n",
            "LOSS train 1.0058336986435785 valid 0.7885428865750631\n",
            "EPOCH 116/500:\n",
            "TRAIN:\n",
            "accuracy: 75.52, precision: 75.76, recall: 75.59, f1-score: 75.62\n",
            "VALIDATION:\n",
            "accuracy: 91.11, precision: 92.24, recall: 90.99, f1-score: 91.21\n",
            "LOSS train 1.0468539396921794 valid 0.8039618531862894\n",
            "EPOCH 117/500:\n",
            "TRAIN:\n",
            "accuracy: 74.95, precision: 75.19, recall: 75.01, f1-score: 75.07\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0198545853296916 valid 0.7854741414388021\n",
            "EPOCH 118/500:\n",
            "TRAIN:\n",
            "accuracy: 75.52, precision: 75.69, recall: 75.61, f1-score: 75.53\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.44, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0206182665295072 valid 0.8030937910079956\n",
            "EPOCH 119/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 74.84, recall: 74.62, f1-score: 74.69\n",
            "VALIDATION:\n",
            "accuracy: 90.37, precision: 91.44, recall: 90.28, f1-score: 90.48\n",
            "LOSS train 1.0322740077972412 valid 0.8574940164883932\n",
            "EPOCH 120/500:\n",
            "TRAIN:\n",
            "accuracy: 77.59, precision: 77.71, recall: 77.65, f1-score: 77.56\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0273192988501654 valid 0.869193454583486\n",
            "EPOCH 121/500:\n",
            "TRAIN:\n",
            "accuracy: 72.88, precision: 73.26, recall: 72.96, f1-score: 72.94\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0540730555852253 valid 0.844023605187734\n",
            "EPOCH 122/500:\n",
            "TRAIN:\n",
            "accuracy: 73.45, precision: 73.48, recall: 73.57, f1-score: 73.45\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.039162039756775 valid 0.7854236563046774\n",
            "EPOCH 123/500:\n",
            "TRAIN:\n",
            "accuracy: 74.39, precision: 74.92, recall: 74.45, f1-score: 74.60\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.046258999241723 valid 0.7778718868891398\n",
            "EPOCH 124/500:\n",
            "TRAIN:\n",
            "accuracy: 76.27, precision: 76.60, recall: 76.36, f1-score: 76.39\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.76, recall: 89.49, f1-score: 89.64\n",
            "LOSS train 0.9833081960678101 valid 0.8309621810913086\n",
            "EPOCH 125/500:\n",
            "TRAIN:\n",
            "accuracy: 75.52, precision: 75.67, recall: 75.63, f1-score: 75.53\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 0.9995603561401367 valid 0.7874043385187784\n",
            "EPOCH 126/500:\n",
            "TRAIN:\n",
            "accuracy: 73.82, precision: 73.92, recall: 73.98, f1-score: 73.83\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0433911946084764 valid 0.8274531364440918\n",
            "EPOCH 127/500:\n",
            "TRAIN:\n",
            "accuracy: 75.89, precision: 76.08, recall: 76.00, f1-score: 75.89\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.031848152478536 valid 0.8303413391113281\n",
            "EPOCH 128/500:\n",
            "TRAIN:\n",
            "accuracy: 73.82, precision: 73.97, recall: 73.88, f1-score: 73.88\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0362452268600464 valid 0.8286520640055338\n",
            "EPOCH 129/500:\n",
            "TRAIN:\n",
            "accuracy: 76.27, precision: 76.63, recall: 76.36, f1-score: 76.35\n",
            "VALIDATION:\n",
            "accuracy: 88.89, precision: 90.03, recall: 88.77, f1-score: 88.93\n",
            "LOSS train 1.0373101499345567 valid 0.8424138228098551\n",
            "EPOCH 130/500:\n",
            "TRAIN:\n",
            "accuracy: 74.58, precision: 74.97, recall: 74.65, f1-score: 74.74\n",
            "VALIDATION:\n",
            "accuracy: 89.63, precision: 90.71, recall: 89.57, f1-score: 89.77\n",
            "LOSS train 1.0535883638593886 valid 0.8422883749008179\n",
            "EPOCH 131/500:\n"
          ]
        }
      ],
      "source": [
        "# Load the hyperparameters for training\n",
        "EPOCHS = cfg.train.num_epochs\n",
        "BATCH_SIZE = cfg.train.batch_size\n",
        "LEARNING_RATE = cfg.train.learning_rate\n",
        "OPTI = cfg.train.optimizer\n",
        "EARLY_STOPPING = cfg.train.early_stopping\n",
        "PATIENCE = cfg.train.patience\n",
        "LR_SCHEDULER = cfg.train.lr_scheduler\n",
        "LABEL_SMOOTHING = cfg.train.label_smoothing\n",
        "\n",
        "# Initialization of the metrics' dictionary\n",
        "training_metrics_dict = {\n",
        "    \"model\" : [model.model_name],\n",
        "    \"epoch\": [],\n",
        "    \"loss\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"recall\": [],\n",
        "    \"precision\": [],\n",
        "    \"f1_score\": [],\n",
        "}\n",
        "validation_metrics_dict = {\n",
        "    \"model\" : [model.model_name],\n",
        "    \"epoch\": [],\n",
        "    \"loss\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"recall\": [],\n",
        "    \"precision\": [],\n",
        "    \"f1_score\": [],\n",
        "}\n",
        "\n",
        "# Dataloader initialization for training, validation and test\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Definition of the Categorical Cross Entropy Loss\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing = LABEL_SMOOTHING)\n",
        "\n",
        "# Definition of the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=LR_SCHEDULER, patience=5)\n",
        "\n",
        "train(\n",
        "    EPOCHS, \n",
        "    training_metrics_dict, \n",
        "    validation_metrics_dict, \n",
        "    train_dataloader, \n",
        "    val_dataloader, \n",
        "    model, \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    lr_scheduler, \n",
        "    cfg\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz43RZa3iuRu"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etj9SlVBiuRu"
      },
      "outputs": [],
      "source": [
        "# Path to the model.pt\n",
        "model_path = './testing/model.pt'\n",
        "\n",
        "# Batch size of the dataloader\n",
        "BATCH_SIZE = cfg.train.batch_size\n",
        "\n",
        "# Initialization of the dataloader\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Loss Function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialization of the test metrics dictionary\n",
        "test_metrics_dict = {\n",
        "    \"model\" : [model.model_name],\n",
        "    \"epoch\": [],\n",
        "    \"loss\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"recall\": [],\n",
        "    \"precision\": [],\n",
        "    \"f1_score\": [],\n",
        "}\n",
        "\n",
        "cm = test(\n",
        "    model,\n",
        "    model_path,\n",
        "    test_dataloader,\n",
        "    test_metrics_dict,\n",
        "    loss_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivuBD21_iuRu"
      },
      "source": [
        "# Loss and Accuracy (Training and Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjiZ1_DTiuRu"
      },
      "outputs": [],
      "source": [
        "actual_dir = './training/results/TIM2024-10-03_13:49:30'\n",
        "# TO DO add an intermidiate path with the directories of best models (1 for each possibility)\n",
        "path_training_metrics = actual_dir + '/training_metrics.json'\n",
        "path_validation_metrics = actual_dir+ '/validation_metrics.json'\n",
        "\n",
        "# load the dictionary {'model': [model_name], 'epoch': [1, 2 ...], 'loss': [1.9, 1.8 ...], 'accuracy': [0.6, 0.7, ...], 'recall': [0.2, 0.3, ...], 'precision': [0.3, 0.4, ...], 'f1-score': [0.5, 0.6, ...]}\n",
        "data_training = utils.load_metrics(path_training_metrics)\n",
        "data_validation = utils.load_metrics(path_validation_metrics)\n",
        "\n",
        "# Load the epochs, loss and accuracy in training and validation for the plots\n",
        "epochs = data_training['epoch']\n",
        "training_loss = data_training['loss']\n",
        "training_accuracy = data_training['accuracy']\n",
        "\n",
        "validation_loss = data_validation['loss']\n",
        "validation_accuracy = data_validation['accuracy']\n",
        "\n",
        "# Plot section\n",
        "# 1st Subplot => Loss in Training and Validation\n",
        "# 2nd Subplot => Accuracy in Training and Validation\n",
        "utils.plot_loss_acc(epochs, training_loss, validation_loss, training_accuracy, validation_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaPMYl_ViuRu"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT4TIk1BiuRu"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion Matrix\n",
        "\n",
        "class_names = ['dis', 'gio', 'neu', 'pau', 'rab', 'sor', 'tri']\n",
        "utils.plot_confusion_matrix(cm, class_names, cmap='rocket')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
